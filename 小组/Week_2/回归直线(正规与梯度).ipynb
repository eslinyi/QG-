{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PIRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     452 non-null    float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 55.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "##读取数据\n",
    "df=pd.read_csv('boston_housing_data.csv')\n",
    "##数据预处理\n",
    "print(df.info())  ##数据的可视化，发现MEDV有空数据，需要剔除，我们把这些空数据作为测试集来预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "text=df[df['MEDV'].isnull()]\n",
    "##将测试集存储到文件中\n",
    "text.to_csv(\"波士顿房价测试集.csv\",index=False,sep=',')\n",
    "##然后剔除原数据的空值，然后为了保留上述的过程，所以我没有inplace=TRUE\n",
    "df1=df.dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 对整体数据及集的分析\n",
    "我们不难发现的是，有些数据的大小的相差过大，有超过300的，也有小于1的，这样的话不利于进行线性回归，也就是说我们要进行数据的处理，把他们变小一点，不过这一步可以不去做，因为没有太大的必要，差距再可控范围内。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[ 2.08663654e+01],\n        [-2.38024776e-01],\n        [ 3.82205042e-02],\n        [ 5.13558367e-02],\n        [ 2.43504780e+00],\n        [-1.16579857e+01],\n        [ 5.11015834e+00],\n        [-6.09415860e-03],\n        [-1.27151396e+00],\n        [ 2.94444280e-01],\n        [-1.13598117e-02],\n        [-8.31030389e-01],\n        [ 1.23142862e-02],\n        [-5.20753302e-01]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##回归直线拟合--正规方程法\n",
    "def Linear_fitting(X,Y):\n",
    "    theta=np.linalg.inv(X.T*X)*X.T*Y\n",
    "    return theta\n",
    "##数据处理--转化为矩阵\n",
    "date=np.matrix(df1)\n",
    "X=date[:,0:13]\n",
    "Y=date[:,13]\n",
    "X=np.c_[np.ones(Y.size),X]\n",
    "theta=Linear_fitting(X,Y)\n",
    "theta\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "10.044277819270544"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##代价函数，测试拟合效果\n",
    "def Cost_funtion(X,Y,theta):\n",
    "    cost=np.power(((X*theta)-Y),2)\n",
    "    return np.sum(cost)/(2*len(X))\n",
    "cost=Cost_funtion(X,Y,theta)\n",
    "cost\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " 从上述的代价可以看出，本次拟合效果相对来说还是比较好的，符合要求，这个时候我们就可以用此次模型来对缺失的数据进行填充"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[533.34132286],\n        [305.7592669 ],\n        [314.7522323 ],\n        [266.08603437],\n        [279.16885241],\n        [269.39089315],\n        [294.75251892],\n        [241.88836879],\n        [283.39949055],\n        [361.99350524],\n        [295.189447  ],\n        [310.43509737],\n        [254.38116499],\n        [327.88948149],\n        [291.01069604],\n        [267.64211479],\n        [303.97245818],\n        [297.38699675],\n        [292.32421101],\n        [282.89122957],\n        [282.63662966],\n        [311.11199355],\n        [337.71123046],\n        [343.79043161],\n        [456.3616027 ],\n        [622.4106857 ],\n        [583.94201915],\n        [612.59556695],\n        [455.71170996],\n        [570.37808008],\n        [598.52554267],\n        [551.97908159],\n        [471.10894107],\n        [612.12471094],\n        [455.66497075],\n        [351.5232114 ],\n        [317.25609246],\n        [596.92340564],\n        [399.74755687],\n        [497.28352318],\n        [515.86264646],\n        [512.19456372],\n        [496.86119381],\n        [562.5355185 ],\n        [616.04837584],\n        [507.44091621],\n        [262.55278951],\n        [408.88746658],\n        [556.21238486],\n        [165.88559044],\n        [ 71.32992505],\n        [327.40822041],\n        [287.51859542],\n        [235.93856417]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=text.drop('MEDV',axis=1)\n",
    "date_text=np.matrix(text)\n",
    "X_text=date_text[:,0:13]\n",
    "X_text=np.c_[np.ones(X_text.shape[0]),X_text]\n",
    "Y1=X_text*theta\n",
    "Y1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "上述就是用正规方程法求出来的结果，接下来我继续用梯度下降法来解决这个问题"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[ 23.78821169],\n        [-21.3753154 ],\n        [ 27.15648116],\n        [-11.65912903],\n        [ 22.13905409],\n        [ -2.95510022],\n        [  3.44956767],\n        [ -5.4726575 ],\n        [  3.0400322 ],\n        [ -8.84613101],\n        [ -5.89750501],\n        [ -2.35814797],\n        [  2.17380719],\n        [-16.47472291]])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##要完成梯度下降法，那么我们先是要进行归一化，从而方便我们快速的迭代出我们需要的数据\n",
    "df2=df1\n",
    "train=[]\n",
    "for x in df2.columns.tolist()[0:13]:\n",
    "    s=np.sum(df2[x])\n",
    "    xs=df2[x]/s\n",
    "    train.append(xs)\n",
    "##构建数据--转化为矩阵并且计算\n",
    "datax=np.matrix(train)\n",
    "dataxT=datax.T\n",
    "datay=np.matrix(df2)\n",
    "X_gd=dataxT[:,:13]\n",
    "Y_gd=datay[:,13]\n",
    "X_gd=np.c_[np.ones(Y_gd.size),X_gd]\n",
    "l=X_gd.shape[1]\n",
    "theta_gd=np.zeros(l)\n",
    "theta_gd=np.matrix(theta_gd)\n",
    "theta_gd=theta_gd.T\n",
    "##梯度下降法\n",
    "def Gradient_descent(X,Y,theta,a,num_lisers):\n",
    "    m=Y.size\n",
    "    for i in range(0,num_lisers):\n",
    "        y_hat=np.dot(X[:,1:],theta[1:])+theta[0]\n",
    "        dy=Y-y_hat\n",
    "        theta[0] += a*np.sum(dy)\n",
    "        theta[1:] += a*np.dot(X[:,1:].T,dy)\n",
    "    return theta\n",
    "##计算并获取数据\n",
    "a=0.001\n",
    "num_lisers=5000\n",
    "theta_gd=Gradient_descent(X_gd,Y_gd,theta_gd,a,num_lisers)\n",
    "theta_gd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "38.72065272945117"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##根据上述的结果进行代价运算\n",
    "cost_gd=Cost_funtion(X_gd,Y_gd,theta_gd)\n",
    "cost_gd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " emmmmm,很明显，这次梯度下降的效果就差了很多，不过相对来说，应该问题不是很大，也是差不多的，然后这次的结果我们也可以来计算测试集的值"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[62.53890645],\n        [76.07606688],\n        [76.22201535],\n        [74.86907065],\n        [73.52166794],\n        [75.28281221],\n        [75.20191734],\n        [74.64349671],\n        [75.28666285],\n        [70.0315046 ],\n        [75.66652605],\n        [75.65951535],\n        [75.2140014 ],\n        [74.6815855 ],\n        [75.34940198],\n        [74.76461843],\n        [75.74377   ],\n        [75.56349246],\n        [75.23605238],\n        [74.94247612],\n        [71.59507126],\n        [74.76006817],\n        [74.11224513],\n        [72.00473338],\n        [65.3464452 ],\n        [56.28403281],\n        [58.51388698],\n        [58.88971151],\n        [66.59951696],\n        [61.66404074],\n        [58.45316299],\n        [57.47177412],\n        [62.338046  ],\n        [57.46919593],\n        [57.71975334],\n        [71.43989479],\n        [69.39477431],\n        [56.99264722],\n        [55.17767663],\n        [56.00537845],\n        [60.23286812],\n        [60.87392737],\n        [61.78670633],\n        [57.48828499],\n        [57.48582058],\n        [59.96551106],\n        [74.67187941],\n        [67.96501954],\n        [58.67696072],\n        [72.26471353],\n        [72.53789245],\n        [73.15643307],\n        [74.22483687],\n        [73.69103141]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2=X_text*theta_gd\n",
    "Y2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "有这两种数据我们可以看到，之前作为测试集的数据，也就是我们剔除的数据，其实是不是很合理的，比较两个结果可以发现按道理来说，不应该是这样的，所以，咳咳，应该不能把这些数据看出测试集，没有参考型，不过可以通过代价函数来看出拟合的效果。而且根据数据的整体情况来看的话，会发现缺失的数据有很大的问题，所以本次的测试集其实是错误的。\n",
    "不过因为本次两种方法得到的模型其实问题比较大，所以接下来继续优化梯度下降法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[ 2.37376096e+01],\n        [-4.82768881e-01],\n        [ 6.13643444e-01],\n        [-2.58403178e-01],\n        [ 4.75255730e-01],\n        [-1.22457336e-01],\n        [-1.65911498e-03],\n        [-1.19556102e-01],\n        [ 4.20008937e-02],\n        [-6.75544604e-01],\n        [-1.29417546e-01],\n        [-1.24177163e-01],\n        [ 5.29574236e-02],\n        [-3.69800280e-01]])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##优化梯度算法\n",
    "def Gradient_descent1(X,Y,theta,a,num_lisers):\n",
    "    m=Y.size\n",
    "    for i in range(0,num_lisers):\n",
    "        theta=theta-(a/m)*X.T*(X*theta-Y)\n",
    "    return theta\n",
    "##对数据进行标准化处理\n",
    "df3=df1\n",
    "train1=[]\n",
    "for x in df3.columns.tolist()[0:13]:\n",
    "    s=np.sum(df2[x])\n",
    "    m=np.mean(df[x])\n",
    "    ms=np.ones(Y.size)*m\n",
    "    xs1=(df3[x]-ms)/s\n",
    "    train1.append(xs1)\n",
    "datax1=np.matrix(train1)\n",
    "dataxT1=datax1.T\n",
    "datay1=np.matrix(df3)\n",
    "X_gd1=dataxT1[:,:13]\n",
    "Y_gd1=datay1[:,13]\n",
    "X_gd1=np.c_[np.ones(Y_gd1.size),X_gd1]\n",
    "l=X_gd1.shape[1]\n",
    "theta_gd1=np.zeros(l)\n",
    "theta_gd1=np.matrix(theta_gd1)\n",
    "theta_gd1=theta_gd1.T\n",
    "a=0.01\n",
    "num_lisers=5000\n",
    "theta_gd1=Gradient_descent1(X_gd1,Y_gd1,theta_gd1,a,num_lisers)\n",
    "theta_gd1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "38.68479001515334"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##代价估计\n",
    "cost_gd1=Cost_funtion(X_gd1,Y_gd1,theta_gd1)\n",
    "cost_gd1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "发现结果并没有变化，已经麻了，不过我觉得问题还是有，在初始化设置theta那里，不过那些都是比较后面的内容，就先不做太多的阐述了"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
